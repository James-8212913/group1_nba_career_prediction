{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37efae11",
   "metadata": {},
   "source": [
    "## Data has already been normalised with all outliers removed. The intent is to build a log regression classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3d107805",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import preprocessing as pp\n",
    "from imblearn.over_sampling import SMOTE as smt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a1648234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'GP', 'FG%', '3P Made', '3PA', '3P%', 'FT%', 'BLK', 'AST', 'DREB',\n",
       "       'FTM', 'REB', 'OREB', 'FTA', 'FGM', 'PTS', 'FGA', 'STL', 'TOV', 'MIN',\n",
       "       'TARGET_5Yrs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import processed data from the processed folder in the project\n",
    "\n",
    "path = '/Users/james/projects/adsi/group1_nba_career_prediction/data/processed'\n",
    "df_train = pd.read_csv(path+'/df_train_norm_outlier.csv')\n",
    "# Get columns names to inform model building \n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "615c365a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      GP  3PA  BLK       AST      DREB       FTM       REB      OREB  \\\n",
      "0     80  0.3  0.2  1.473613  1.259921  1.259921  1.560491  1.300591   \n",
      "1     75 -1.0  0.6  0.887904  1.546680  1.338866  1.875777  1.532619   \n",
      "2     85  1.2  0.2  0.928318  1.216440  0.736806  1.338866  0.843433   \n",
      "3     63  0.8  0.1  1.216440  1.259921  0.965489  1.442250  0.928318   \n",
      "4     63  1.4  0.6  0.736806  1.392477  0.584804  1.698499  1.338866   \n",
      "...   ..  ...  ...       ...       ...       ...       ...       ...   \n",
      "7995  32 -0.2  0.2  0.793701  1.216440  0.736806  1.238562  0.669433   \n",
      "7996  54  0.1  0.3  0.464159  1.032280  0.584804  1.259921  1.000000   \n",
      "7997  85  0.6  0.2  1.503695  1.280579  1.409460  1.458100  1.000000   \n",
      "7998  39 -0.5  0.3  0.584804  0.843433  0.843433  0.965489  0.736806   \n",
      "7999  49  2.4 -0.3  1.518294  1.032280  0.928318  1.062659  0.464159   \n",
      "\n",
      "           FTA       FGM       PTS       FGA       STL       TOV       MIN  \n",
      "0     1.426043  1.442250  1.983192  1.856636  1.032280  1.169607  2.896468  \n",
      "1     1.532619  1.613429  2.189760  1.991632  0.793701  1.118689  2.793522  \n",
      "2     0.843433  1.238562  1.650964  1.650964  0.736806  0.843433  2.673075  \n",
      "3     1.144714  1.518294  2.016530  1.885204  0.736806  1.238562  2.673075  \n",
      "4     0.793701  1.193483  1.546680  1.503695  0.736806  0.887904  2.610999  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "7995  0.843433  0.887904  1.216440  1.216440  0.669433  0.736806  2.095379  \n",
      "7996  0.736806  0.887904  1.216440  1.118689  0.843433  0.669433  1.817121  \n",
      "7997  1.574061  1.587401  2.203575  2.080084  1.062659  1.216440  3.043802  \n",
      "7998  0.887904  1.000000  1.357209  1.320006  0.669433  0.793701  1.974681  \n",
      "7999  1.091393  1.193483  1.686865  1.721301  0.965489  1.118689  2.677732  \n",
      "\n",
      "[8000 rows x 15 columns]\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "7995    1\n",
      "7996    1\n",
      "7997    1\n",
      "7998    1\n",
      "7999    1\n",
      "Name: TARGET_5Yrs, Length: 8000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "preds = df_train[['GP', '3PA', 'BLK', 'AST', 'DREB','FTM', 'REB', 'OREB', 'FTA', 'FGM', 'PTS', 'FGA', 'STL', 'TOV', 'MIN']]\n",
    "tgt = df_train['TARGET_5Yrs']\n",
    "print(preds)\n",
    "print(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a183379a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888     1\n",
       "6085    1\n",
       "5607    1\n",
       "2348    1\n",
       "4526    1\n",
       "       ..\n",
       "4294    1\n",
       "5000    1\n",
       "4612    1\n",
       "4672    1\n",
       "5392    1\n",
       "Name: TARGET_5Yrs, Length: 1600, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the Data into test and train sets\n",
    "\n",
    "preds_train, preds_test, tgt_train, tgt_test = train_test_split(preds, tgt, test_size=0.20, random_state=5, stratify=tgt)\n",
    "preds_train\n",
    "tgt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fedd711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.66421003, -1.09416563,  0.35980865, ...,  0.75918561,\n",
       "        -0.78126502, -1.01640658],\n",
       "       [ 0.55297109,  0.58330729, -0.12366298, ...,  0.32127878,\n",
       "        -0.04759224,  0.91964283],\n",
       "       [ 2.01358843, -0.30476661, -0.12366298, ...,  1.6238734 ,\n",
       "         2.63660362,  2.38614824],\n",
       "       ...,\n",
       "       [-1.02936436,  0.28728266, -0.60713461, ..., -0.91181388,\n",
       "        -0.04759224, -0.73343523],\n",
       "       [ 0.30953486, -1.39019026, -0.12366298, ..., -0.21042377,\n",
       "        -1.00725399, -0.89634344],\n",
       "       [-0.29905569,  0.78065704, -0.60713461, ...,  0.070274  ,\n",
       "         0.25279976,  0.48725666]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a scaler for the data \n",
    "\n",
    "scaler = pp.StandardScaler().fit(preds_train)\n",
    "preds_scaled = scaler.transform(preds_train)\n",
    "preds_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1bdcd1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 10670\n",
      "6400 10670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       GP       3PA       BLK       AST      DREB       FTM       REB  \\\n",
       " 0      52 -0.300000  0.300000  0.965489  0.965489  0.736806  1.144714   \n",
       " 1      72  1.400000  0.200000  1.320006  1.392477  1.238562  1.503695   \n",
       " 2      96  0.500000  0.200000  1.473613  1.885204  1.532619  1.930979   \n",
       " 3      53 -0.500000  0.600000  1.032280  1.032280  0.928318  1.216440   \n",
       " 4      88 -0.100000  0.400000  1.091393  1.626133  1.698499  1.817121   \n",
       " ...    ..       ...       ...       ...       ...       ...       ...   \n",
       " 10665  70  0.456758  0.249249  0.702614  1.345987  0.982486  1.625323   \n",
       " 10666  72 -1.013173  0.028942  1.489173  1.300584  1.231516  1.482170   \n",
       " 10667  55  2.057091  0.168826  1.136601  0.817595  0.809204  0.893221   \n",
       " 10668  72 -0.490404  0.203199  1.313840  1.183648  1.060494  1.352572   \n",
       " 10669  52  1.008370 -0.094978  1.355223  1.090403  0.844854  1.258809   \n",
       " \n",
       "            OREB       FTA       FGM       PTS       FGA       STL       TOV  \\\n",
       " 0      0.843433  0.843433  0.965489  1.320006  1.300591  0.965489  0.887904   \n",
       " 1      0.887904  1.375069  1.600521  2.175767  2.016530  0.887904  1.032280   \n",
       " 2      1.062659  1.721301  1.875777  2.540668  2.466212  1.118689  1.560491   \n",
       " 3      0.928318  1.091393  1.193483  1.626133  1.546680  0.669433  1.032280   \n",
       " 4      1.193483  1.846915  2.102944  2.818919  2.644786  1.216440  1.426043   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 10665  1.259921  1.157348  1.347951  1.811895  1.806291  0.734078  1.015898   \n",
       " 10666  0.961903  1.381408  1.345762  1.848949  1.779021  0.873327  1.295179   \n",
       " 10667  0.911937  0.911773  1.118689  1.582309  1.570337  0.549153  0.887904   \n",
       " 10668  0.940312  1.212512  1.276846  1.744749  1.672566  0.785561  1.145697   \n",
       " 10669  0.841648  0.999422  1.301232  1.776330  1.744054  0.739336  1.112296   \n",
       " \n",
       "             MIN  \n",
       " 0      2.168703  \n",
       " 1      2.951058  \n",
       " 2      3.543671  \n",
       " 3      2.369285  \n",
       " 4      3.674181  \n",
       " ...         ...  \n",
       " 10665  2.566038  \n",
       " 10666  2.580801  \n",
       " 10667  2.017638  \n",
       " 10668  2.517635  \n",
       " 10669  2.662911  \n",
       " \n",
       " [10670 rows x 15 columns],\n",
       " 0        1\n",
       " 1        0\n",
       " 2        1\n",
       " 3        0\n",
       " 4        1\n",
       "         ..\n",
       " 10665    0\n",
       " 10666    0\n",
       " 10667    0\n",
       " 10668    0\n",
       " 10669    0\n",
       " Name: TARGET_5Yrs, Length: 10670, dtype: int64)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Balance out the TGT set of data using SMOTE from imbalanced-learn\n",
    "\n",
    "sm = smt(random_state = 22)\n",
    "preds_train_smt, tgt_train_smt = sm.fit_resample(preds_train, tgt_train)\n",
    "print(len(tgt_train),len(tgt_train_smt))\n",
    "print(len(preds_train), len(preds_train_smt))\n",
    "preds_train_smt, tgt_train_smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1d531377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a model and train it\n",
    "\n",
    "log_mod = LR(max_iter = 10000)\n",
    "log_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f3803b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the best number of iterations for the model using cross validation grid search\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "grid\n",
    "log_mod_cv=GridSearchCV(log_mod,grid,cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "eedef8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/projects/adsi/adsi/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "70 fits failed out of a total of 140.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/james/projects/adsi/adsi/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/james/projects/adsi/adsi/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/james/projects/adsi/adsi/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/james/projects/adsi/adsi/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.8334375         nan 0.83375           nan 0.83421875\n",
      "        nan 0.83390625        nan 0.83375           nan 0.83359375\n",
      "        nan 0.83359375]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Train the model\n",
    "\n",
    "#fit_log_mod = clf.fit(preds_train_smt, tgt_train_smt)\n",
    "#fit_log_mod\n",
    "\n",
    "fit_cv_log_mod = log_mod_cv.fit(preds_train, tgt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "81dc35f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.1, 'penalty': 'l2'}\n",
      "accuracy : 0.83421875\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",fit_cv_log_mod.best_params_)\n",
    "print(\"accuracy :\",fit_cv_log_mod.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4b54be74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy for the model is: 83.390625\n"
     ]
    }
   ],
   "source": [
    "## Check the results \n",
    "\n",
    "train_acc = fit_cv_log_mod.score(preds_train, tgt_train)\n",
    "print('The training accuracy for the model is: {}'.format(train_acc*100))\n",
    "\n",
    "## This is not a great result - it may need more or less features in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7fcb63d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make predictions on the test set\n",
    "tgt_preds = fit_cv_log_mod.predict(preds_test)\n",
    "len(tgt_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1b47e3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy for the model is: 83.5625\n"
     ]
    }
   ],
   "source": [
    "## Check the results in the test model \n",
    "\n",
    "test_acc = accuracy_score(tgt_test, tgt_preds)\n",
    "print('The testing accuracy for the model is: {}'.format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3c85d981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.03      0.06       266\n",
      "           1       0.84      1.00      0.91      1334\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.73      0.51      0.48      1600\n",
      "weighted avg       0.80      0.84      0.77      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Get a classification report\n",
    "\n",
    "print(classification_report(tgt_test, tgt_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9934a911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApcAAAGDCAYAAAB+wzuBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnNUlEQVR4nO3dedgXdb3/8ecbyH0DF1TQIylWZGod8phbpqmQGlbulmgUWdpiq536pWad0+IpLc0OaYpmiJUmpmke0lxKA/c9ySVRXFFcAAV8//74zk23xL1w33PP977nfj685mLmM/Od+QxdF9er92c+M5GZSJIkSWUY0OwOSJIkqT4Ml5IkSSqN4VKSJEmlMVxKkiSpNIZLSZIklcZwKUmSpNIYLiX1iIhYNSIujYh5EfGrbpznsIj4Q5l9a4aI+H1EjG92PySppxkupX4uIg6NiJkR8VJEzClC0E4lnHp/YCiwbmYe0NWTZOb5mblnCf15nYjYNSIyIi5epn2bov2aTp7nhIj4RUfHZebYzJzcxe5KUp9huJT6sYj4PHAK8F80guCmwE+AcSWc/t+Av2Xm4hLO1VOeBt4VEeu2ahsP/K2sC0SD/9ZK6jf8B0/qpyJibeCbwNGZeVFmvpyZizLz0sz8UnHMyhFxSkQ8XiynRMTKxb5dI2J2RHwhIp4qqp5HFvtOBL4BHFRURCcsW+GLiM2KCuGgYvuIiHgwIl6MiIci4rBW7de3+t0OETGjGG6fERE7tNp3TUScFBE3FOf5Q0Ss185fw6vAb4GDi98PBA4Czl/m7+rUiHg0Il6IiJsjYueifQzwn63u8/ZW/fh2RNwAzAfeWLR9rNh/RkT8ptX5vxsR0yMiOvu/nyT1VoZLqf96F7AKcHE7x3wN2B7YFtgG2A74eqv9GwJrA8OACcDpETE4M4+nUQ2dmplrZOZZ7XUkIlYHfgSMzcw1gR2A25Zz3BDgsuLYdYEfAJctU3k8FDgS2ABYCfhie9cGzgUOL9b3Au4CHl/mmBk0/g6GAL8EfhURq2TmFcvc5zatfvMRYCKwJvDIMuf7AvC2IjjvTOPvbnz6PV5JNWC4lPqvdYFnOhi2Pgz4ZmY+lZlPAyfSCE0tFhX7F2Xm5cBLwJu62J/XgK0iYtXMnJOZdy/nmL2BBzLzvMxcnJlTgPuAfVsdc3Zm/i0zFwAX0giFbcrMPwNDIuJNNELmucs55heZ+Wxxzf8BVqbj+zwnM+8ufrNomfPNp/H3+APgF8CnM3N2B+eTpD7BcCn1X88C67UMS7dhY15fdXukaFt6jmXC6XxgjRXtSGa+TGM4+ihgTkRcFhFv7kR/Wvo0rNX2E13oz3nAMcB7WE4lNyK+GBH3FkPxz9Oo1rY33A7waHs7M/Mm4EEgaIRgSaoFw6XUf/0FeAXYr51jHqcxMafFpvzrkHFnvQys1mp7w9Y7M/PKzNwD2IhGNfJnnehPS58e62KfWpwHfAq4vKgqLlUMW38ZOBAYnJnrAPNohEKAtoay2x3ijoijaVRAHy/OL0m1YLiU+qnMnEdj0s3pEbFfRKwWEW+IiLER8b3isCnA1yNi/WJizDdoDON2xW3ALhGxaTGZ6KstOyJiaESMK569fIXG8PpryznH5cCWxeuTBkXEQcAo4Hdd7BMAmfkQ8G4az5gua01gMY2Z5YMi4hvAWq32PwlstiIzwiNiS+BbwIdpDI9/OSK27VrvJal3MVxK/Vjx/ODnaUzSeZrGUO4xNGZQQyMAzQTuAO4EbinaunKtq4Cpxblu5vWBcEDRj8eBuTSC3ieXc45ngX1oTIh5lkbFb5/MfKYrfVrm3Ndn5vKqslcCV9B4PdEjwEJeP+Td8oL4ZyPilo6uUzyG8Avgu5l5e2Y+QGPG+XktM/ElqS8LJydKkiSpLFYuJUmSVBrDpSRJkkpjuJQkSVJpDJeSJEkqjeFSkiRJpWnvyxxNtXBx+y8glqQWDzzxUrO7IKmPeNvwNaLjo3rWqm8/ptsZZ8GtpzX9PtrSa8OlJElSLXX+mwt9kuFSkiSpStFri46lMFxKkiRVqeaVy3rfnSRJkipl5VKSJKlKDotLkiSpNDUfFjdcSpIkVanmlct6R2dJkiRVysqlJElSlRwWlyRJUmlqPixuuJQkSaqSlUtJkiSVpuaVy3pHZ0mSJFXKyqUkSVKVHBaXJElSaWo+LG64lCRJqpKVS0mSJJWm5uGy3ncnSZKkSlm5lCRJqtIAn7mUJElSWWo+LG64lCRJqlLNZ4vXOzpLkiSpUlYuJUmSquSwuCRJkkpT82Fxw6UkSVKVrFxKkiSpNDWvXNY7OkuSJKlShktJkqQqxYDuLx1dIuLnEfFURNzVqu37EXFfRNwRERdHxDqt9n01ImZFxP0RsVer9jFF26yIOK4zt2e4lCRJqlJE95eOnQOMWabtKmCrzNwa+Bvw1UZ3YhRwMPDW4jc/iYiBETEQOB0YC4wCDimObZfhUpIkqUoVVC4z81pg7jJtf8jMxcXmjcDwYn0ccEFmvpKZDwGzgO2KZVZmPpiZrwIXFMe2y3ApSZJUpRIqlxExMSJmtlomrmAvPgr8vlgfBjzaat/soq2t9nY5W1ySJKmPycxJwKSu/DYivgYsBs4vtVMFw6UkSVKVmviey4g4AtgH2D0zs2h+DNik1WHDizbaaW+Tw+KSJElVquCZy+VeNmIM8GXg/Zk5v9WuacDBEbFyRIwARgJ/BWYAIyNiRESsRGPSz7SOrmPlUpIkqUoVvEQ9IqYAuwLrRcRs4Hgas8NXBq6KRh9uzMyjMvPuiLgQuIfGcPnRmbmkOM8xwJXAQODnmXl3h9f+Z0W0d1m4mN7ZMUm9zgNPvNTsLkjqI942fI2mfx5n1fef0e2Ms2DaJ5t+H22xcilJklQlvy0uSZKk0tT82+KGS0mSpCpZuZQkSVJpal65rHd0liRJUqWsXEqSJFUoal65NFxKkiRVyHApSZKk8tQ7W/rMpSRJkspj5VKSJKlCDotLkiSpNIZLSZIklcZwKUmSpNLUPVw6oUeSJEmlsXIpSZJUpXoXLg2XkiRJVar7sLjhUpIkqUKGS0mSJJWm7uHSCT2SJEkqjZVLSZKkCtW9cmm4lCRJqlK9s6XhUpIkqUp1r1z6zKUkSZJKY+VSkiSpQnWvXBouJUmSKmS4lCRJUnnqnS0Nl5IkSVWqe+XSCT2SJEkqjZVLSZKkCtW9cmm4lCRJqpDhUpIkSaUxXEqSJKk89c6WTuiRJElSeaxcSpIkVchhcUmSJJXGcClJkqTS1D1c+sylJEmSSmPlUpIkqUr1LlwaLiVJkqpU92Fxw6UkSVKFDJdSL3He5HO46De/IiIYOXJLvvnt/2bllVdudrckNcEzTz3Bj7/zDeY9Nxci2GPvD7D3hw5l6uT/ZfplF7PWOoMBOHTC0bzjP3Zi8eJFnHHySTw06z6WLFnCu/fYmw8e+tEm34X6qyrCZUT8HNgHeCoztyrahgBTgc2Ah4EDM/O5aHToVOB9wHzgiMy8pfjNeODrxWm/lZmTO7q24VJ9wpNPPskvzz+Xi6ddziqrrMKXPv9Zrrj8MsZ94IPN7pqkJhg4cCDjjzqWN275FhbMf5kvH/Vhtv737QHYe/9DGXfg4a87/i9/+j8WLVrED868kFcWLuBzHz2AnXYbwwYbbtyM7ktVOAc4DTi3VdtxwPTM/E5EHFdsfwUYC4wslv8AzgD+owijxwOjgQRujohpmflcexd2trj6jCVLlvDKwoUsXryYBQsXsv4GGzS7S5KaZPC66/PGLd8CwKqrrc6wfxvB3GeeavP4iOCVhQtYsmQxr77yCoMGvYFVV1u9qu5KrxMR3V46kpnXAnOXaR4HtFQeJwP7tWo/NxtuBNaJiI2AvYCrMnNuESivAsZ0dO0eq1xGxJuLzg4rmh4DpmXmvT11TdXX0KFDGX/ER9nrve9hlVVW5l077MgOO+7U7G5J6gWeeuJxHp51HyPfshX33X07V/z2Qv70h8vY/E2jGH/Usayx5lpsv8vu/PWGP/HxA/bilVcWcsQnv8Caa63d7K6rv2reI5dDM3NOsf4EMLRYHwY82uq42UVbW+3t6pHKZUR8BbiAxl/fX4slgClFGbat302MiJkRMfOsn03qia6pj3ph3jyu/uN0Lv/DdK66+joWLFjA7y69pNndktRkCxbM5+QTvsQRn/oiq62+Bnvtuz+nnXcJJ0+awuAh6zH5pz8EYNZ9dzNg4AAmXXgFP/nFpVz6q1/w5OOzm9x79VdlVC5bZ6ZimbgifcjMpDHUXbqeqlxOAN6amYtaN0bED4C7ge8s70eZOQmYBLBwcc/csPqmG2/8M8OGD2fIkCEA7P7ePbn91lvZZ99xTe6ZpGZZvHgRJ5/wJXbefSzb77wbAOsMWXfp/vfu/QH++2ufA+C66Vfw9nfuwKBBb2DtwUN401bb8Pe/3cPQjYc3o+vq58qY0NM6M62AJyNio8ycUwx7tzxL8hiwSavjhhdtjwG7LtN+TUcX6alnLl8DlveU9EbFPmmFbLjRxtxx++0sWLCAzOSmG//CiM03b3a3JDVJZvKTk09i+KYj2PeADy9tf+7Zp5eu33T91WyyWePfifU22JC7bp0BwMIFC3jgnjvZeJMR1XZaar5pwPhifTxwSav2w6Nhe2BeMXx+JbBnRAyOiMHAnkVbu3qqcvk5YHpEPMA/x+o3BbYAjumha6rGtt56G/bYcy8OPuADDBw4iDe/5S3sf8BBze6WpCa5767buPaqy9h0xBZ8ceIhQOO1Q9f/8Uoe/vv9QLDBhhvziWP/E4Ax+x3I6d87gc999ADI5D1j3s9mm49s4h2oP6viNZcRMYVG1XG9iJhNY9b3d4ALI2IC8AhwYHH45TReQzSLxquIjgTIzLkRcRIwozjum5m57CShf712Y8i9fBExANiO10/omZGZSzrze4fFJXXWA0+81OwuSOoj3jZ8jaa/wXzkl67odsZ54Ptjmn4fbemx2eKZ+RpwY0+dX5IkqS+q+Qd6fM+lJEmSyuMXeiRJkirkt8UlSZJUmppnS8OlJElSlQYMqHe6NFxKkiRVqO6VSyf0SJIkqTRWLiVJkirkhB5JkiSVpubZ0nApSZJUJSuXkiRJKk3dw6UTeiRJklQaK5eSJEkVqnnh0nApSZJUpboPixsuJUmSKlTzbOkzl5IkSSqPlUtJkqQKOSwuSZKk0tQ8WxouJUmSqmTlUpIkSaWpebZ0Qo8kSZLKY+VSkiSpQg6LS5IkqTQ1z5aGS0mSpCpZuZQkSVJpap4tndAjSZKk8li5lCRJqpDD4pIkSSpNzbOl4VKSJKlKda9c+sylJEmSSmPlUpIkqUJ1r1waLiVJkipU82xpuJQkSaqSlUtJkiSVpubZ0gk9kiRJKo+VS0mSpAo5LC5JkqTS1DxbGi4lSZKqNKDm6dJwKUmSVKGaZ0sn9EiSJKk8Vi4lSZIqVPcJPVYuJUmSKjQgur90JCKOjYi7I+KuiJgSEatExIiIuCkiZkXE1IhYqTh25WJ7VrF/s27dX3d+LEmSpBUTEd1eOjj/MOAzwOjM3AoYCBwMfBf4YWZuATwHTCh+MgF4rmj/YXFclxkuJUmS6mcQsGpEDAJWA+YAuwG/LvZPBvYr1scV2xT7d49ujN0bLiVJkioUUcYSEyNiZqtlYsv5M/Mx4GTgHzRC5TzgZuD5zFxcHDYbGFasDwMeLX67uDh+3a7eX4fhMiK+FxFrRcQbImJ6RDwdER/u6gUlSZL6syjhv8yclJmjWy2Tlp4/YjCNauQIYGNgdWBMVffXmcrlnpn5ArAP8DCwBfClnuyUJElSXVUwoee9wEOZ+XRmLgIuAnYE1imGyQGGA48V648BmwAU+9cGnu3y/XXimJZO7A38KjPndfVikiRJ/V1PT+ihMRy+fUSsVjw7uTtwD3A1sH9xzHjgkmJ9WrFNsf+PmZldvb/OvOfydxFxH7AA+GRErA8s7OoFJUmS1HMy86aI+DVwC7AYuBWYBFwGXBAR3yrazip+chZwXkTMAubSmFneZdGZYBoRQ4B5mbkkIlYH1szMJ7pz4Y4sXEyXE7Ok/uWBJ15qdhck9RFvG75G099gvt+ZM7udcX77sdFNv4+2dGZCz2rAp4AziqaNgdE92SlJkqS6GhDR7aU368wzl2cDrwI7FNuPAd/qsR5JkiTVWBmvIurNOhMuN8/M7wGLADJzPtDLb0uSJEnN0JkJPa9GxKrQeAYyIjYHXunRXkmSJNVUNz5+0yd0JlweD1wBbBIR59N4T9IRPdkpSZKkuqp5tuw4XGbmVRFxC7A9jeHwz2bmMz3eM0mSpBrq7RNyuqvDcBkRuxSrLxZ/jooIMvPanuuWJElSPdU7WnZuWLz1px5XAbaj8fHz3XqkR5IkSeqzOjMsvm/r7YjYBDilpzokSZJUZ07o+VezgbeU3RFJkqT+YEC9s2Wnnrn8MSz9FOMAYFsa36qUJEnSCrJyCTNbrS8GpmTmDT3UH0mSpFqrebbs1DOXk6voiCRJkvq+NsNlRNzJP4fDX7cLyMzcusd6JUmSVFP9eVh8n8p6IUmS1E/02wk9mflIlR2RJEnqD+peuRzQ0QERsX1EzIiIlyLi1YhYEhEvVNE5SZIk9S2dmS1+GnAw8CtgNHA4sGVPdkqSJKmu6l237ETlEiAzZwEDM3NJZp4NjOnZbkmSJNXTgIhuL71ZZyqX8yNiJeC2iPgeMIdOhlJJkiS9Xi/Pht3WZkiMiHcWqx8pjjsGeBnYBPhQz3dNkiSpfiKi20tv1l7lclJErAFcQOOrPPcAJ1bTLUmSJPVFbVYuM/PtNN51uRj4dUTcHhHHRcRmVXVOkiSpbiK6v/Rm7T47mZn3Z+aJmTmKxizxtYHpEeG3xSVJkrrACT1ARAwANgCGAqsDT/VkpyRJkuqql2fDbms3XEbEzsAhwH7AnTSevzw2M+f1fNckSZLqp7dPyOmuNsNlRDwKPEIjUJ6QmVYrJUmS1K72Kpc7+X1xSX3Bdvse1+wuSOojFtx6WrO7UPuXhbcZLg2WkiRJ5eu3w+KSJEkq34B6Z8vaV2YlSZJUofYm9PwYyLb2Z+ZneqRHkiRJNVb3ymV7w+IzK+uFJElSP9Fvn7nMzMlVdkSSJKk/6M+VSwAiYn3gK8AoYJWW9szcrQf7JUmSVEs1L1x2akLP+cC9wAjgROBhYEYP9kmSJEl9VGdeRbRuZp4VEZ/NzD8Bf4oIw6UkSVIXDKh56bIz4XJR8eeciNgbeBwY0nNdkiRJqq+6vweyM+HyWxGxNvAF4MfAWsCxPdorSZKkmqp54bLjcJmZvytW5wHv6dnuSJIk1Vu/HxaPiLNZzsvUM/OjPdIjSZIkdUtErAOcCWxFI8d9FLgfmApsRmOC9oGZ+Vw0Xrx5KvA+YD5wRGbe0tVrd2bY/3fAZcUyncaw+EtdvaAkSVJ/FtH9pRNOBa7IzDcD29B4889xwPTMHEkj0x1XHDsWGFksE4EzunN/nRkW/03r7YiYAlzfnYtKkiT1Vz39EvVirswuwBEAmfkq8GpEjAN2LQ6bDFxD413m44BzMzOBGyNinYjYKDPndOX6XZmwNBLYoCsXkyRJ6u8GRHR7iYiJETGz1TKx1SVGAE8DZ0fErRFxZkSsDgxtFRifAIYW68OAR1v9fnbR1iWdeebyRV7/zOUTNFKuJEmSmiAzJwGT2tg9CHgH8OnMvCkiTuWfQ+Atv8+I+Jc5NWXozLD4mj1xYUmSpP6ogsnis4HZmXlTsf1rGuHyyZbh7ojYCHiq2P8YsEmr3w8v2rqkw2HxiJjemTZJkiR1bEB0f2lPZj4BPBoRbyqadgfuAaYB44u28cAlxfo04PBo2B6Y19XnLaGdymVErAKsBqwXEYOBlltZi26Mw0uSJPVnQc+XLoFPA+dHxErAg8CRNIqKF0bEBOAR4MDi2MtpvIZoFo1XER3ZnQu3Nyz+CeBzwMbAzfwzXL4AnNadi0qSJPVXPT1bHCAzbwNGL2fX7ss5NoGjy7p2m+EyM08FTo2IT2fmj8u6oCRJkuqrM68ieq14yzsAETE4Ij7Vc12SJEmqr55+5rLZOhMuP56Zz7dsZOZzwMd7rEeSJEk1Fo33VHZr6c06fBURMDAiohiPJyIGAiv1bLckSZLqqbdXHrurM+HyCmBqRPxvsf2Jok2SJEkrqJcXHrutM+HyKzQ+Yv7JYvsq4Gc91iNJkiT1WZ35Qs9rwE+LhYjYGfgxJU5ZlyRJ6i8G1Lx02ZnKJRHxduAQGi/bfAi4qCc7JUmSVFf99pnLiNiSRqA8BHgGmApEZr6nor5JkiTVTs0Ll+1WLu8DrgP2ycxZABFxbCW9kiRJUp/U3nsuPwjMAa6OiJ9FxO5QzccwJUmS6moA0e2lN2szXGbmbzPzYODNwNU0vjO+QUScERF7VtQ/SZKkWono/tKbdfiFnsx8OTN/mZn7AsOBW2m8nkiSJEkrqO6ff+zUbPEWxacfJxWLJEmSVlDdX0XUmW+LS5IkSZ2yQpVLSZIkdU/NC5eGS0mSpCrVfVjccClJklShmmdLw6UkSVKV6j7hpe73J0mSpApZuZQkSapQ1Hxc3HApSZJUoXpHS8OlJElSpeo+W9xnLiVJklQaK5eSJEkVqnfd0nApSZJUqZqPihsuJUmSquRscUmSJJWm7hNe6n5/kiRJqpCVS0mSpAo5LC5JkqTS1DtaGi4lSZIqVffKpc9cSpIkqTRWLiVJkipU98qe4VKSJKlCdR8WN1xKkiRVqN7R0nApSZJUqZoXLms/7C9JkqQKWbmUJEmq0ICaD4wbLiVJkirksLgkSZJKEyX816nrRAyMiFsj4nfF9oiIuCkiZkXE1IhYqWhfudieVezfrDv3Z7iUJEmqUET3l076LHBvq+3vAj/MzC2A54AJRfsE4Lmi/YfFcV1muJQkSaqZiBgO7A2cWWwHsBvw6+KQycB+xfq4Ypti/+7RjZdxGi4lSZIqNIDo9hIREyNiZqtl4jKXOQX4MvBasb0u8HxmLi62ZwPDivVhwKMAxf55xfFd4oQeSZKkCpUxoSczJwGTln/+2Ad4KjNvjohdu3+1FWO4lCRJqlAFs8V3BN4fEe8DVgHWAk4F1omIQUV1cjjwWHH8Y8AmwOyIGASsDTzb1Ys7LC5JklQjmfnVzByemZsBBwN/zMzDgKuB/YvDxgOXFOvTim2K/X/MzOzq9Q2XkiRJFarqVUTL8RXg8xExi8YzlWcV7WcB6xbtnweO6879OSwuSZJUoQEVvkQ9M68BrinWHwS2W84xC4EDyrqm4VKSJKlC3ag89gmGS0mSpAr5+UdJkiSpk6xcSpIkVchhcUmSJJWmygk9zWC4lCRJqpCVS6mXGLvHbqy2+uoMHDCAgYMGMuXCi5rdJUkV+unxhzF2l614eu6LjD7gvwD4xqf2Zp93b81rmTw990UmHv8L5jw9j4PHjubzR+xBRPDS/IV85r+mcuffGh8jOfqQXTnygzsQEZx90Q2c9strmnhX6o/qPqHHcKk+5cyzJzN48JBmd0NSE5x36Y38dOqfOPOkw5e2/XDydL75k8sA+NQh7+arE8fymW9fwMOPP8ueHzuF519cwJ47juL0rx/CLoefzKjNN+LID+7Azh/5Pq8uWsK00z/F5dfdxYOPPtOs25Jqx9nikqQ+4YZb/s7cefNf1/biywuXrq+26sq0fLHuxtsf4vkXFwDw1zseYtjQdQB484gNmXHXwyxYuIglS17juptnsd9u21bSf6lFlLD0ZlYu1XcEHPXxCUQE+x9wEPsfeFCzeySpFzjh6H05bJ/tmPfSAsZM/NG/7D9ivx248oZ7ALj7749zwjH7MmTt1VnwyquM2emt3HLPP6rusvq5ATUfF6+8chkRR7azb2JEzIyImWf9bFKV3VIfcM55U5j664s5/ac/Y+qU87l55oxmd0lSL3DC6Zcycuz/44Lfz+Sog3Z53b5dRo9k/H7v4uunXgLA/Q89yf+ccxWX/uRopp1+NLffP5slS15rRrfVj9W9ctmMYfET29qRmZMyc3Rmjp7w8YlV9kl9wNChQwFYd9112e29e3DXnXc0uUeSepOpl89gv923Xbq91ciNOeMbh3LAsZOYO+/lpe2Tf/sXdjzse+wx4RSef2E+DzzyVBN6K9VXj4TLiLijjeVOYGhPXFP1Nn/+fF5++aWl63/58w1sscXIJvdKUrNtvun6S9f32XVr/vbwkwBssuFgLjj540z4f+cy6x+vD4/rD15j6THjdtuGqb+fWV2HJah96bKnnrkcCuwFPLdMewB/7qFrqsbmPvssx37maAAWL1nC+/behx133qWDX0mqk8n/fQQ7//tI1ltnDWZdcRIn/fRyxuz0Vkb+2wa89lryjzlz+cy3LwDgqxPHMmSd1Tnlq41nsxcveY2dDvseAFNO/hhD1lmdRYuX8LnvXMi8lxY07Z7UP9X9PZfRMrOu1JNGnAWcnZnXL2ffLzPz0I7OsXAx5XdMUi0Nfucxze6CpD5iwa2nNT3Z/fXBed3OONu9ce2m30dbeqRymZkT2tnXYbCUJEmqq16bCkviey4lSZJUGt9zKUmSVKWaly4Nl5IkSRWq+4Qew6UkSVKFav6BHsOlJElSlWqeLZ3QI0mSpPJYuZQkSapSzUuXhktJkqQKOaFHkiRJpan7hB6fuZQkSVJprFxKkiRVqOaFS8OlJElSpWqeLg2XkiRJFXJCjyRJkkrjhB5JkiSpk6xcSpIkVajmhUvDpSRJUqVqni4Nl5IkSRVyQo8kSZJK44QeSZIkqZOsXEqSJFWo5oVLw6UkSVKlap4uDZeSJEkVqvuEHp+5lCRJUmkMl5IkSRWK6P7S/vljk4i4OiLuiYi7I+KzRfuQiLgqIh4o/hxctEdE/CgiZkXEHRHxju7cn+FSkiSpQlHC0oHFwBcycxSwPXB0RIwCjgOmZ+ZIYHqxDTAWGFksE4EzunN/hktJkqQq9XC6zMw5mXlLsf4icC8wDBgHTC4OmwzsV6yPA87NhhuBdSJio67enhN6JEmSKlTlhJ6I2Ax4O3ATMDQz5xS7ngCGFuvDgEdb/Wx20TaHLrByKUmS1MdExMSImNlqmbicY9YAfgN8LjNfaL0vMxPInuiblUtJkqQKlfH5x8ycBExq+xrxBhrB8vzMvKhofjIiNsrMOcWw91NF+2PAJq1+Prxo6xIrl5IkSRXq6Qk9ERHAWcC9mfmDVrumAeOL9fHAJa3aDy9mjW8PzGs1fL7CrFxKkiRVqecfudwR+AhwZ0TcVrT9J/Ad4MKImAA8AhxY7LsceB8wC5gPHNmdixsuJUmSKtTTE3oy83rajrC7L+f4BI4u6/oOi0uSJKk0Vi4lSZIqVMaEnt7McClJklShmmdLw6UkSVKlap4ufeZSkiRJpbFyKUmSVKEqP//YDIZLSZKkCjmhR5IkSaWpebY0XEqSJFWp7pVLJ/RIkiSpNFYuJUmSKlXv0qXhUpIkqUJ1HxY3XEqSJFWo5tnScClJklSlulcundAjSZKk0li5lCRJqpBf6JEkSVJ56p0tDZeSJElVqnm29JlLSZIklcfKpSRJUoXqPlvccClJklQhJ/RIkiSpPPXOloZLSZKkKtU8WzqhR5IkSeWxcilJklQhJ/RIkiSpNE7okSRJUmnqXrn0mUtJkiSVxnApSZKk0jgsLkmSVKG6D4sbLiVJkirkhB5JkiSVpu6VS5+5lCRJUmmsXEqSJFWo5oVLw6UkSVKlap4uDZeSJEkVckKPJEmSSuOEHkmSJKmTrFxKkiRVqOaFS8OlJElSpWqeLg2XkiRJFar7hB6fuZQkSVJprFxKkiRVqO6zxSMzm90HqdMiYmJmTmp2PyT1fv57ITWHw+LqayY2uwOS+gz/vZCawHApSZKk0hguJUmSVBrDpfoan5+S1Fn+eyE1gRN6JEmSVBorl5IkSSqN4VJ9RkSMiYj7I2JWRBzX7P5I6p0i4ucR8VRE3NXsvkj9keFSfUJEDAROB8YCo4BDImJUc3slqZc6BxjT7E5I/ZXhUn3FdsCszHwwM18FLgDGNblPknqhzLwWmNvsfkj9leFSfcUw4NFW27OLNkmS1IsYLiVJklQaw6X6iseATVptDy/aJElSL2K4VF8xAxgZESMiYiXgYGBak/skSZKWYbhUn5CZi4FjgCuBe4ELM/Pu5vZKUm8UEVOAvwBviojZETGh2X2S+hO/0CNJkqTSWLmUJElSaQyXkiRJKo3hUpIkSaUxXEqSJKk0hktJkiSVxnApqUMRsSQibouIuyLiVxGxWjfOdU5E7F+snxkRo9o5dteI2KEL13g4ItZbpu3siPjEMm37RcTvO9NXSVLnGC4ldcaCzNw2M7cCXgWOar0zIgZ15aSZ+bHMvKedQ3YFVjhctmEKjZfvt3Zw0S5JKonhUtKKug7YoqgqXhcR04B7ImJgRHw/ImZExB0tVcJoOC0i7o+I/wM2aDlRRFwTEaOL9TERcUtE3B4R0yNiMxoh9tiiarpzRKwfEb8prjEjInYsfrtuRPwhIu6OiDOBWE6/pwNvjoiNit+sDrwX+G1EfKM4310RMSki/uX3rauhETE6Iq5pOU9E/Dwi/hoRt0bEuKL9rUXbbcXfx8gy/vIlqbczXErqtKJCORa4s2h6B/DZzNwSmADMy8x3Au8EPh4RI4APAG8CRgGHs5xKZESsD/wM+FBmbgMckJkPAz8FflhUTa8DTi223wl8CDizOMXxwPWZ+VbgYmDTZa+RmUuA3wAHFk37Atdk5gvAaZn5zqIyuyqwzwr8tXwN+GNmbge8B/h+EVyPAk7NzG2B0cDsFTinJPVZXRrKktTvrBoRtxXr1wFn0QiJf83Mh4r2PYGtWz2juDYwEtgFmFKEu8cj4o/LOf/2wLUt58rMuW30473AqFaFxbUiYo3iGh8sfntZRDzXxu+nACfTCKkHA+cV7e+JiC8DqwFDgLuBS9s4x7L2BN4fEV8stlehEW7/AnwtIoYDF2XmA508nyT1aYZLSZ2xoKjALVUEvJdbNwGfzswrlznufSX2YwCwfWYuXE5fOuPPwEYRsQ2NcHxwRKwC/AQYnZmPRsQJNALishbzz9Ge1vuDRsX1/mWOvzcibgL2Bi6PiE9k5vKCtSTVisPikspyJfDJiHgDQERsWQwPXwscVDyTuRGNoeNl3QjsUgyjExFDivYXgTVbHfcH4NMtGxGxbbF6LXBo0TYWGLy8DmZmAlOBycDvi5DaEhSfKaqgbc0Ofxj492L9Q8vc96dbntOMiLcXf74ReDAzfwRcAmzdxnklqVYMl5LKciZwD3BLRNwF/C+N0ZGLgQeKfefSGC5+ncx8GpgIXBQRt9MIgNAYmv5Ay4Qe4DPA6GKCzD38c9b6iTTC6d00hsf/0U4/pwDbFH+Smc/TeN7zLhpBcUYbvzsRODUiZgJLWrWfBLwBuKO4/klF+4HAXcXjBFsV9y5JtReN/yMvSZIkdZ+VS0mSJJXGcClJkqTSGC4lSZJUGsOlJEmSSmO4lCRJUmkMl5IkSSqN4VKSJEmlMVxKkiSpNP8fX2MmRxLNsH0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm=confusion_matrix(tgt_test,tgt_preds)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(cm, annot=True,fmt='d', cmap='Blues')\n",
    "plt.ylabel(\"Actual Values\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "25fd292c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'GP', 'FG%', '3P Made', '3PA', '3P%', 'FT%', 'BLK', 'AST', 'DREB',\n",
       "       'FTM', 'REB', 'OREB', 'FTA', 'FGM', 'PTS', 'FGA', 'STL', 'TOV', 'MIN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import test data set\n",
    "\n",
    "path = '/Users/james/projects/adsi/group1_nba_career_prediction/data/processed'\n",
    "df_test = pd.read_csv(path+'/df_test_norm_outlier.csv')\n",
    "# Get columns names to inform model building \n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9c59fa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>3PA</th>\n",
       "      <th>BLK</th>\n",
       "      <th>AST</th>\n",
       "      <th>DREB</th>\n",
       "      <th>FTM</th>\n",
       "      <th>REB</th>\n",
       "      <th>OREB</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FGM</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGA</th>\n",
       "      <th>STL</th>\n",
       "      <th>TOV</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.736806</td>\n",
       "      <td>0.928318</td>\n",
       "      <td>0.887904</td>\n",
       "      <td>1.193483</td>\n",
       "      <td>1.062659</td>\n",
       "      <td>1.062659</td>\n",
       "      <td>1.169607</td>\n",
       "      <td>1.587401</td>\n",
       "      <td>1.546680</td>\n",
       "      <td>0.584804</td>\n",
       "      <td>0.928318</td>\n",
       "      <td>2.087759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.518294</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>1.216440</td>\n",
       "      <td>1.144714</td>\n",
       "      <td>0.793701</td>\n",
       "      <td>1.357209</td>\n",
       "      <td>1.546680</td>\n",
       "      <td>2.161592</td>\n",
       "      <td>2.008299</td>\n",
       "      <td>0.843433</td>\n",
       "      <td>1.216440</td>\n",
       "      <td>2.682373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.357209</td>\n",
       "      <td>1.488806</td>\n",
       "      <td>1.216440</td>\n",
       "      <td>1.650964</td>\n",
       "      <td>1.091393</td>\n",
       "      <td>1.392477</td>\n",
       "      <td>1.698499</td>\n",
       "      <td>2.244017</td>\n",
       "      <td>2.196689</td>\n",
       "      <td>1.091393</td>\n",
       "      <td>1.259921</td>\n",
       "      <td>3.236433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.600521</td>\n",
       "      <td>1.473613</td>\n",
       "      <td>1.650964</td>\n",
       "      <td>1.709976</td>\n",
       "      <td>1.144714</td>\n",
       "      <td>1.846915</td>\n",
       "      <td>1.894536</td>\n",
       "      <td>2.659006</td>\n",
       "      <td>2.514581</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>1.532619</td>\n",
       "      <td>3.548971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.144714</td>\n",
       "      <td>0.843433</td>\n",
       "      <td>1.032280</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>0.584804</td>\n",
       "      <td>1.091393</td>\n",
       "      <td>1.169607</td>\n",
       "      <td>1.675069</td>\n",
       "      <td>1.587401</td>\n",
       "      <td>0.793701</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>2.308350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>84</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.144714</td>\n",
       "      <td>1.320006</td>\n",
       "      <td>1.193483</td>\n",
       "      <td>1.574061</td>\n",
       "      <td>1.238562</td>\n",
       "      <td>1.357209</td>\n",
       "      <td>1.503695</td>\n",
       "      <td>2.056710</td>\n",
       "      <td>1.885204</td>\n",
       "      <td>0.843433</td>\n",
       "      <td>1.259921</td>\n",
       "      <td>2.767655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.736806</td>\n",
       "      <td>1.409460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.638643</td>\n",
       "      <td>1.193483</td>\n",
       "      <td>1.238562</td>\n",
       "      <td>1.426043</td>\n",
       "      <td>1.856636</td>\n",
       "      <td>1.875777</td>\n",
       "      <td>0.736806</td>\n",
       "      <td>0.887904</td>\n",
       "      <td>2.535494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>53</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.736806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843433</td>\n",
       "      <td>1.193483</td>\n",
       "      <td>0.887904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928318</td>\n",
       "      <td>1.280579</td>\n",
       "      <td>1.216440</td>\n",
       "      <td>0.736806</td>\n",
       "      <td>0.793701</td>\n",
       "      <td>2.147229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>89</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.546680</td>\n",
       "      <td>1.587401</td>\n",
       "      <td>1.357209</td>\n",
       "      <td>1.765174</td>\n",
       "      <td>1.144714</td>\n",
       "      <td>1.426043</td>\n",
       "      <td>1.754411</td>\n",
       "      <td>2.438499</td>\n",
       "      <td>2.276638</td>\n",
       "      <td>1.091393</td>\n",
       "      <td>1.338866</td>\n",
       "      <td>3.370800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.843433</td>\n",
       "      <td>1.259921</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>1.375069</td>\n",
       "      <td>0.887904</td>\n",
       "      <td>1.032280</td>\n",
       "      <td>1.032280</td>\n",
       "      <td>1.442250</td>\n",
       "      <td>1.357209</td>\n",
       "      <td>0.669433</td>\n",
       "      <td>1.062659</td>\n",
       "      <td>2.289428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3799 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GP  3PA  BLK       AST      DREB       FTM       REB      OREB  \\\n",
       "0     56  0.3  0.3  0.736806  0.928318  0.887904  1.193483  1.062659   \n",
       "1     43  1.7 -0.0  1.518294  0.965489  1.216440  1.144714  0.793701   \n",
       "2     82  1.9  0.3  1.357209  1.488806  1.216440  1.650964  1.091393   \n",
       "3     86  1.8  0.1  1.600521  1.473613  1.650964  1.709976  1.144714   \n",
       "4     58  1.7  0.2  1.144714  0.843433  1.032280  0.965489  0.584804   \n",
       "...   ..  ...  ...       ...       ...       ...       ...       ...   \n",
       "3794  84 -0.0  0.3  1.144714  1.320006  1.193483  1.574061  1.238562   \n",
       "3795  49 -0.4  0.4  0.736806  1.409460  1.000000  1.638643  1.193483   \n",
       "3796  53 -0.6  0.2  0.736806  1.000000  0.843433  1.193483  0.887904   \n",
       "3797  89  1.2  0.3  1.546680  1.587401  1.357209  1.765174  1.144714   \n",
       "3798  55  0.6  0.2  0.843433  1.259921  0.965489  1.375069  0.887904   \n",
       "\n",
       "           FTA       FGM       PTS       FGA       STL       TOV       MIN  \n",
       "0     1.062659  1.169607  1.587401  1.546680  0.584804  0.928318  2.087759  \n",
       "1     1.357209  1.546680  2.161592  2.008299  0.843433  1.216440  2.682373  \n",
       "2     1.392477  1.698499  2.244017  2.196689  1.091393  1.259921  3.236433  \n",
       "3     1.846915  1.894536  2.659006  2.514581  0.965489  1.532619  3.548971  \n",
       "4     1.091393  1.169607  1.675069  1.587401  0.793701  0.965489  2.308350  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3794  1.357209  1.503695  2.056710  1.885204  0.843433  1.259921  2.767655  \n",
       "3795  1.238562  1.426043  1.856636  1.875777  0.736806  0.887904  2.535494  \n",
       "3796  1.000000  0.928318  1.280579  1.216440  0.736806  0.793701  2.147229  \n",
       "3797  1.426043  1.754411  2.438499  2.276638  1.091393  1.338866  3.370800  \n",
       "3798  1.032280  1.032280  1.442250  1.357209  0.669433  1.062659  2.289428  \n",
       "\n",
       "[3799 rows x 15 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lbl = preds.columns\n",
    "df_test[pred_lbl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ab1bc328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3799"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_prob_log = fit_cv_log_mod.predict_proba(df_test[pred_lbl])\n",
    "x = test_pred_prob_log[:,1]\n",
    "len(x)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1d904a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.950057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.767826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>0.936996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>0.842460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>0.770981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>0.953664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>0.788216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3799 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TARGET_5Yrs\n",
       "0        0.801511\n",
       "1        0.750911\n",
       "2        0.930788\n",
       "3        0.950057\n",
       "4        0.767826\n",
       "...           ...\n",
       "3794     0.936996\n",
       "3795     0.842460\n",
       "3796     0.770981\n",
       "3797     0.953664\n",
       "3798     0.788216\n",
       "\n",
       "[3799 rows x 1 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_prob = pd.DataFrame(test_pred_prob_log[:,1])\n",
    "test_pred_prob.columns = ['TARGET_5Yrs']\n",
    "test_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "d52fbaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.950057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.767826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>0.936996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>0.842460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>0.770981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>0.953664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>0.788216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3799 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TARGET_5Yrs\n",
       "0        0.801511\n",
       "1        0.750911\n",
       "2        0.930788\n",
       "3        0.950057\n",
       "4        0.767826\n",
       "...           ...\n",
       "3794     0.936996\n",
       "3795     0.842460\n",
       "3796     0.770981\n",
       "3797     0.953664\n",
       "3798     0.788216\n",
       "\n",
       "[3799 rows x 1 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Id = pd.DataFrame(df_test['Id'])\n",
    "Id\n",
    "test_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "505c7263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.801511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8194</td>\n",
       "      <td>0.750911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.930788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8196</td>\n",
       "      <td>0.950057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8197</td>\n",
       "      <td>0.767826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>8175</td>\n",
       "      <td>0.936996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>8176</td>\n",
       "      <td>0.842460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>8178</td>\n",
       "      <td>0.770981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>8181</td>\n",
       "      <td>0.953664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>8183</td>\n",
       "      <td>0.788216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  TARGET_5Yrs\n",
       "0        1     0.801511\n",
       "1     8194     0.750911\n",
       "2        3     0.930788\n",
       "3     8196     0.950057\n",
       "4     8197     0.767826\n",
       "...    ...          ...\n",
       "3794  8175     0.936996\n",
       "3795  8176     0.842460\n",
       "3796  8178     0.770981\n",
       "3797  8181     0.953664\n",
       "3798  8183     0.788216\n",
       "\n",
       "[3799 rows x 2 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = Id.join(test_pred_prob)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "8daf35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('/Users/james/projects/adsi/group1_nba_career_prediction/models/model_4_1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
